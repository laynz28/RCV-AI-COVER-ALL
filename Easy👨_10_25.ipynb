{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laynz28/RCV-AI-COVER-ALL/blob/main/Easy%F0%9F%91%A8_10_25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[![smaller.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEAAAAASCAYAAADrL9giAAAAAXNSR0IB2cksfwAAAAlwSFlzAAALEwAACxMBAJqcGAAABOlJREFUeJzdWAlMVEcYXqs9IxEJtjTVqmmbtAkRVhQPqq1HlUtrKlas2tYQDjlEUc5djoXlEuhCBDkKu4AgKLuc6y6wyHKIoGlTTqmlKTclUm2b1jZFeV/nDe2a5RIiSu0mXzLz5v/n/d8330zeLIczwQ/JJhsh3ZvB1PLamWvCn5jrob8+lWgIGWJqfFtxYVcq4WQ0EdexxJdBaa9ibqSAGbj0/0LrWaDoUDHhqD8ZeS7q/IeYfvncF/u4QLhBfaqXcH1jDPnVBrjCH5rzAp8QUHmih4igqxGAkX+uZPpLpky621kCv9AUeIUkU/DDU1Aoy8b9vrknNGP0FQMFtmn/Wt+QaUseeVhSdVkuFm8QjkPMGfG42N87i+HAC9NAfC6RCDW7W6urSfpoc3wTM0K4L+cgxzJ+OvtelCAeJb0+GHqmgRpY2X0xLramIhMcEwd85iXE/hMCzF/rCGGsaNbIh4hE8AqPerR52PPgvIUrh1GfvD6dBBdeIhVAn+uDlw3dNdC1y0J5c7VWrH9UDBZtcsFI/2jf2T8ceu+70nbuxRS8tcuD9q0c/fEbccsv3xfBZL8XvMOj8eoHx7DlCI86prtZinWfeGPxey7g7vPEjzfy6dzPr3fCsp3uGGjLh2foaZqzlPSl0tSZiaCwv8Rh6oP6phNsfkREBVhi7PlAACMPzBe1IPZqg1bsh84B2GnP1/TZ1X9mjSO6GqV4gRSfkBpPLbzC4jjiSbtckU4dk5iWgIL8VNoeJGTlxWKExcWiv00G3c0uuJCXAkWJhI6nZyUhWZKAlzYeRXN9DqIS4qC/xXVGAkDl+i0RQDAtAd62jBjdAubR0LUWQeegGAsivwYnrRvq1iqt2OWEWGR8rKb/kWsg3tlzkj5jnXHvn/Ngw0Ef+EVGwycimq4g65jM7CQ8t84Jf/XKcZqQMnfgw+ywL+atccBXteeRlZOMZ00d8Wd3CSyJg3TedcZ2Ox5MD3jTrXa/f6YCVD58C/zRJYe+WSgVYN6XnZQ0i3kEh5RNWi9lD0C2EIVcQonmkxVlC84gKxYZH0ftPEzIsav64oajdNz6aADsfENpvhM/nNq+t0VGSTfW5VBRWAfd7SqGIz8MRjanaOweIuxuknv7u0JUlWeipSF3ZltAaS/nINv8DDMw9SHYWi+l5HW3xYAj7oFe5g+obatCe0cFRsbEqssyqEV1NjljEbHtAkL+eHAkEUmOOx2FxB3uWLXXE69sc4ONu4CK9Lq5O1IkZ2k+u5IB0TH0XFho5kzFWLLVFQbb3ej4PvcgKqJMlop6dRYWEgeYHfah71MS0acvAD0E3TgQcw2ZBk+GaY3EZFBkh2OVtRAr7dPpym/NuzZpbG9NCMpz/DS4WR6oNX67QQj1RR6uFfIx3BRBn12+wMOteiFt10j56CNzsO2bqiBU5/HQURFEY9hnt66GoCKXh8G60fhOtQCqHB46K4MmrWlCXDnGII27YvRboMCqjGkSgGkKnhQjjcEQlUux9Fw7BKVFU8b+59EoAKQ7xA8+hSXc1xjVp3fmvLAnBCg+HkA6V0/7PpBOLkOqQz/PdXGPnbxy/yDh+ubEN8J045Uo2n2ZqfeY80JnHXVuQKGVDBJjg6n/E5AYc5CxejPyLZJwyaYHpbb3UHoATydsh6Gw6YRsRyzhtJYc+OP4/g0y+rzVxj9THAAAAABJRU5ErkJggg==)](https://paypal.me/lesantillan)"
      ],
      "metadata": {
        "id": "Vc01O8jLgcFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install to Google Drive (for Resuming Training & Automatic Saving)\n",
        "#@markdown <small> This Notebook is based on another found in: https://github.com/ardha27/AI-Song-Cover-RVC < Visit this repo to read more and support.\n",
        "%cd /content\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from IPython.display import clear_output\n",
        "from ipywidgets import Button\n",
        "import os\n",
        "if not os.path.exists('/content/drive'):\n",
        "    print(\"Your drive is not mounted. Creating Fake Drive.\")\n",
        "    os.makedirs('/content/drive/MyDrive')\n",
        "source = \"Rejekts\"\n",
        "!wget https://huggingface.co/{source}/project/resolve/main/project-main.zip -O '/content/project-main.zip' && unzip -n 'project-main.zip' -d /content/drive/MyDrive\n",
        "!cd '/content/drive/MyDrive/project-main' && python download_files.py && pip install -r 'requirements-safe.txt'\n",
        "!pip install pyngrok tensorflow==2.12.0\n",
        "!rm /content/project-main.zip\n",
        "!rm -r /content/sample_data\n",
        "!mkdir -p /content/dataset\n",
        "clear_output()\n",
        "Button(description=\"\\u2714 Success\", button_style=\"success\")"
      ],
      "metadata": {
        "id": "Sb5fzhzEXK8X",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.Preprocess Data\n",
        "%cd /content/drive/MyDrive/project-main\n",
        "model_name = 'My-Voice' #@param {type:\"string\"}\n",
        "#@markdown <small> Enter the path to your dataset folder (a folder with audios of the vocals you will train on), or if you want just upload the audios using the File Manager into the 'dataset' folder.\n",
        "dataset_folder = '/content/dataset' #@param {type:\"string\"}\n",
        "while len(os.listdir(dataset_folder)) < 1:\n",
        "    input(\"Your dataset folder is empty.\")\n",
        "!mkdir -p ./logs/{model_name}\n",
        "with open(f'./logs/{model_name}/preprocess.log','w') as f:\n",
        "    print(\"Starting...\")\n",
        "!python infer/modules/train/preprocess.py {dataset_folder} 40000 2 ./logs/{model_name} False 3.0 > /dev/null 2>&1\n",
        "with open(f'./logs/{model_name}/preprocess.log','r') as f:\n",
        "    if 'end preprocess' in f.read():\n",
        "        clear_output()\n",
        "        display(Button(description=\"\\u2714 Success\", button_style=\"success\"))\n",
        "    else:\n",
        "        print(\"Error preprocessing data... Make sure your dataset folder is correct.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "w4wXvoez9Rce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.Extract Features\n",
        "f0method = \"rmvpe_gpu\" # @param [\"pm\", \"harvest\", \"rmvpe\", \"rmvpe_gpu\"]\n",
        "%cd /content/drive/MyDrive/project-main\n",
        "with open(f'./logs/{model_name}/extract_f0_feature.log','w') as f:\n",
        "    print(\"Starting...\")\n",
        "if f0method != \"rmvpe_gpu\":\n",
        "    !python infer/modules/train/extract/extract_f0_print.py ./logs/{model_name} 2 {f0method}\n",
        "else:\n",
        "    !python infer/modules/train/extract/extract_f0_rmvpe.py 1 0 0 ./logs/{model_name} True\n",
        "!python infer/modules/train/extract_feature_print.py cuda:0 1 0 0 ./logs/{model_name} v2\n",
        "with open(f'./logs/{model_name}/extract_f0_feature.log','r') as f:\n",
        "    if 'all-feature-done' in f.read():\n",
        "        clear_output()\n",
        "        display(Button(description=\"\\u2714 Success\", button_style=\"success\"))\n",
        "    else:\n",
        "        print(\"Error preprocessing data... Make sure your data was preprocessed.\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "G0MEhFM19Vq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3.Train Index\n",
        "import numpy as np\n",
        "import faiss\n",
        "%cd /content/drive/MyDrive/project-main\n",
        "def train_index(exp_dir1, version19):\n",
        "    exp_dir = \"logs/%s\" % (exp_dir1)\n",
        "    os.makedirs(exp_dir, exist_ok=True)\n",
        "    feature_dir = (\n",
        "        \"%s/3_feature256\" % (exp_dir)\n",
        "        if version19 == \"v1\"\n",
        "        else \"%s/3_feature768\" % (exp_dir)\n",
        "    )\n",
        "    if not os.path.exists(feature_dir):\n",
        "        return \"请先进行特征提取!\"\n",
        "    listdir_res = list(os.listdir(feature_dir))\n",
        "    if len(listdir_res) == 0:\n",
        "        return \"请先进行特征提取！\"\n",
        "    infos = []\n",
        "    npys = []\n",
        "    for name in sorted(listdir_res):\n",
        "        phone = np.load(\"%s/%s\" % (feature_dir, name))\n",
        "        npys.append(phone)\n",
        "    big_npy = np.concatenate(npys, 0)\n",
        "    big_npy_idx = np.arange(big_npy.shape[0])\n",
        "    np.random.shuffle(big_npy_idx)\n",
        "    big_npy = big_npy[big_npy_idx]\n",
        "    if big_npy.shape[0] > 2e5:\n",
        "        infos.append(\"Trying doing kmeans %s shape to 10k centers.\" % big_npy.shape[0])\n",
        "        yield \"\\n\".join(infos)\n",
        "        try:\n",
        "            big_npy = (\n",
        "                MiniBatchKMeans(\n",
        "                    n_clusters=10000,\n",
        "                    verbose=True,\n",
        "                    batch_size=256 * config.n_cpu,\n",
        "                    compute_labels=False,\n",
        "                    init=\"random\",\n",
        "                )\n",
        "                .fit(big_npy)\n",
        "                .cluster_centers_\n",
        "            )\n",
        "        except:\n",
        "            info = traceback.format_exc()\n",
        "            logger.info(info)\n",
        "            infos.append(info)\n",
        "            yield \"\\n\".join(infos)\n",
        "\n",
        "    np.save(\"%s/total_fea.npy\" % exp_dir, big_npy)\n",
        "    n_ivf = min(int(16 * np.sqrt(big_npy.shape[0])), big_npy.shape[0] // 39)\n",
        "    infos.append(\"%s,%s\" % (big_npy.shape, n_ivf))\n",
        "    yield \"\\n\".join(infos)\n",
        "    index = faiss.index_factory(256 if version19 == \"v1\" else 768, \"IVF%s,Flat\" % n_ivf)\n",
        "    infos.append(\"training\")\n",
        "    yield \"\\n\".join(infos)\n",
        "    index_ivf = faiss.extract_index_ivf(index)  #\n",
        "    index_ivf.nprobe = 1\n",
        "    index.train(big_npy)\n",
        "    faiss.write_index(\n",
        "        index,\n",
        "        \"%s/trained_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n",
        "        % (exp_dir, n_ivf, index_ivf.nprobe, exp_dir1, version19),\n",
        "    )\n",
        "\n",
        "    infos.append(\"adding\")\n",
        "    yield \"\\n\".join(infos)\n",
        "    batch_size_add = 8192\n",
        "    for i in range(0, big_npy.shape[0], batch_size_add):\n",
        "        index.add(big_npy[i : i + batch_size_add])\n",
        "    faiss.write_index(\n",
        "        index,\n",
        "        \"%s/added_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n",
        "        % (exp_dir, n_ivf, index_ivf.nprobe, exp_dir1, version19),\n",
        "    )\n",
        "    infos.append(\n",
        "        \"成功构建索引，added_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n",
        "        % (n_ivf, index_ivf.nprobe, exp_dir1, version19)\n",
        "    )\n",
        "\n",
        "training_log = train_index(model_name, 'v2')\n",
        "\n",
        "for line in training_log:\n",
        "    print(line)\n",
        "    if 'adding' in line:\n",
        "        clear_output()\n",
        "        display(Button(description=\"\\u2714 Success\", button_style=\"success\"))"
      ],
      "metadata": {
        "cellView": "form",
        "id": "3KyMRbK49g__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4.Train Model\n",
        "#@markdown <small> Enter your ngrok authtoken to open tensorboard. Get one here: https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "ngrok_authtoken = \"\"#@param {type:\"string\"}\n",
        "!ngrok config add-authtoken {ngrok_authtoken}\n",
        "#%cd /content/drive/MyDrive/project-main\n",
        "from random import shuffle\n",
        "import json\n",
        "import os\n",
        "import pathlib\n",
        "from subprocess import Popen, PIPE, STDOUT\n",
        "from pyngrok import ngrok\n",
        "now_dir=os.getcwd()\n",
        "#@markdown <small> Enter the name of your model again. It must be the same you chose before.\n",
        "model_name = 'My-Voice'#@param {type:\"string\"}\n",
        "#@markdown <small> Choose how often to save the model and how much training you want it to have.\n",
        "save_frequency = 20 # @param {type:\"slider\", min:5, max:50, step:5}\n",
        "epochs = 400 # @param {type:\"slider\", min:10, max:1000, step:10}\n",
        "#@markdown <small> ONLY cache datasets under 10 minutes long. Otherwise leave this unchecked.\n",
        "cache = True #@param {type:\"boolean\"}\n",
        "# Remove the logging setup\n",
        "\n",
        "def click_train(\n",
        "    exp_dir1,\n",
        "    sr2,\n",
        "    if_f0_3,\n",
        "    spk_id5,\n",
        "    save_epoch10,\n",
        "    total_epoch11,\n",
        "    batch_size12,\n",
        "    if_save_latest13,\n",
        "    pretrained_G14,\n",
        "    pretrained_D15,\n",
        "    gpus16,\n",
        "    if_cache_gpu17,\n",
        "    if_save_every_weights18,\n",
        "    version19,\n",
        "):\n",
        "    # 生成filelist\n",
        "    exp_dir = \"%s/logs/%s\" % (now_dir, exp_dir1)\n",
        "    os.makedirs(exp_dir, exist_ok=True)\n",
        "    gt_wavs_dir = \"%s/0_gt_wavs\" % (exp_dir)\n",
        "    feature_dir = (\n",
        "        \"%s/3_feature256\" % (exp_dir)\n",
        "        if version19 == \"v1\"\n",
        "        else \"%s/3_feature768\" % (exp_dir)\n",
        "    )\n",
        "    if if_f0_3:\n",
        "        f0_dir = \"%s/2a_f0\" % (exp_dir)\n",
        "        f0nsf_dir = \"%s/2b-f0nsf\" % (exp_dir)\n",
        "        names = (\n",
        "            set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)])\n",
        "            & set([name.split(\".\")[0] for name in os.listdir(feature_dir)])\n",
        "            & set([name.split(\".\")[0] for name in os.listdir(f0_dir)])\n",
        "            & set([name.split(\".\")[0] for name in os.listdir(f0nsf_dir)])\n",
        "        )\n",
        "    else:\n",
        "        names = set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)]) & set(\n",
        "            [name.split(\".\")[0] for name in os.listdir(feature_dir)]\n",
        "        )\n",
        "    opt = []\n",
        "    for name in names:\n",
        "        if if_f0_3:\n",
        "            opt.append(\n",
        "                \"%s/%s.wav|%s/%s.npy|%s/%s.wav.npy|%s/%s.wav.npy|%s\"\n",
        "                % (\n",
        "                    gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    feature_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    f0_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    f0nsf_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    spk_id5,\n",
        "                )\n",
        "            )\n",
        "        else:\n",
        "            opt.append(\n",
        "                \"%s/%s.wav|%s/%s.npy|%s\"\n",
        "                % (\n",
        "                    gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    feature_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    spk_id5,\n",
        "                )\n",
        "            )\n",
        "    fea_dim = 256 if version19 == \"v1\" else 768\n",
        "    if if_f0_3:\n",
        "        for _ in range(2):\n",
        "            opt.append(\n",
        "                \"%s/logs/mute/0_gt_wavs/mute%s.wav|%s/logs/mute/3_feature%s/mute.npy|%s/logs/mute/2a_f0/mute.wav.npy|%s/logs/mute/2b-f0nsf/mute.wav.npy|%s\"\n",
        "                % (now_dir, sr2, now_dir, fea_dim, now_dir, now_dir, spk_id5)\n",
        "            )\n",
        "    else:\n",
        "        for _ in range(2):\n",
        "            opt.append(\n",
        "                \"%s/logs/mute/0_gt_wavs/mute%s.wav|%s/logs/mute/3_feature%s/mute.npy|%s\"\n",
        "                % (now_dir, sr2, now_dir, fea_dim, spk_id5)\n",
        "            )\n",
        "    shuffle(opt)\n",
        "    with open(\"%s/filelist.txt\" % exp_dir, \"w\") as f:\n",
        "        f.write(\"\\n\".join(opt))\n",
        "\n",
        "    # Replace logger.debug, logger.info with print statements\n",
        "    print(\"Write filelist done\")\n",
        "    print(\"Use gpus:\", str(gpus16))\n",
        "    if pretrained_G14 == \"\":\n",
        "        print(\"No pretrained Generator\")\n",
        "    if pretrained_D15 == \"\":\n",
        "        print(\"No pretrained Discriminator\")\n",
        "    if version19 == \"v1\" or sr2 == \"40k\":\n",
        "        config_path = \"configs/v1/%s.json\" % sr2\n",
        "    else:\n",
        "        config_path = \"configs/v2/%s.json\" % sr2\n",
        "    config_save_path = os.path.join(exp_dir, \"config.json\")\n",
        "    if not pathlib.Path(config_save_path).exists():\n",
        "        with open(config_save_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            with open(config_path, \"r\") as config_file:\n",
        "                config_data = json.load(config_file)\n",
        "                json.dump(\n",
        "                    config_data,\n",
        "                    f,\n",
        "                    ensure_ascii=False,\n",
        "                    indent=4,\n",
        "                    sort_keys=True,\n",
        "                )\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "    cmd = (\n",
        "        'python infer/modules/train/train.py -e \"%s\" -sr %s -f0 %s -bs %s -g %s -te %s -se %s %s %s -l %s -c %s -sw %s -v %s'\n",
        "        % (\n",
        "            exp_dir1,\n",
        "            sr2,\n",
        "            1 if if_f0_3 else 0,\n",
        "            batch_size12,\n",
        "            gpus16,\n",
        "            total_epoch11,\n",
        "            save_epoch10,\n",
        "            \"-pg %s\" % pretrained_G14 if pretrained_G14 != \"\" else \"\",\n",
        "            \"-pd %s\" % pretrained_D15 if pretrained_D15 != \"\" else \"\",\n",
        "            1 if if_save_latest13 == True else 0,\n",
        "            1 if if_cache_gpu17 == True else 0,\n",
        "            1 if if_save_every_weights18 == True else 0,\n",
        "            version19,\n",
        "        )\n",
        "    )\n",
        "    # Use PIPE to capture the output and error streams\n",
        "    p = Popen(cmd, shell=True, cwd=now_dir, stdout=PIPE, stderr=STDOUT, bufsize=1, universal_newlines=True)\n",
        "\n",
        "    # Print the command's output as it runs\n",
        "    for line in p.stdout:\n",
        "        print(line.strip())\n",
        "\n",
        "    # Wait for the process to finish\n",
        "    p.wait()\n",
        "    return \"训练结束, 您可查看控制台训练日志或实验文件夹下的train.log\"\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./logs --port=8888\n",
        "print(\"Tensorboard NGROK URL:\",end=\"\")\n",
        "ngrok_url = ngrok.connect(8888)\n",
        "print(ngrok_url)\n",
        "try:\n",
        "    training_log = click_train(\n",
        "        model_name,\n",
        "        '40k',\n",
        "        True,\n",
        "        0,\n",
        "        save_frequency,\n",
        "        epochs,\n",
        "        12,\n",
        "        True,\n",
        "        'assets/pretrained_v2/f0G40k.pth',\n",
        "        'assets/pretrained_v2/f0D40k.pth',\n",
        "        0,\n",
        "        cache,\n",
        "        True,\n",
        "        'v2',\n",
        "    )\n",
        "    print(training_log)\n",
        "except:\n",
        "    ngrok.kill()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "FFfC9x239kC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Installation\n",
        "!pip install yt_dlp\n",
        "!pip install ffmpeg\n",
        "!mkdir youtubeaudio"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xx7TMiXIVxIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Youtube WAV\n",
        "from __future__ import unicode_literals\n",
        "import yt_dlp\n",
        "import ffmpeg\n",
        "import sys\n",
        "\n",
        "#@markdown Don't give space for song name\n",
        "url = \"https://youtu.be/-EeRwcogblc?si=Cp585euxpqVW3zla\" #@param {type:\"string\"}\n",
        "song_name = \"Idol\" #@param {type:\"string\"}\n",
        "\n",
        "ydl_opts = {\n",
        "    'format': 'bestaudio/best',\n",
        "#    'outtmpl': 'output.%(ext)s',\n",
        "    'postprocessors': [{\n",
        "        'key': 'FFmpegExtractAudio',\n",
        "        'preferredcodec': 'wav',\n",
        "    }],\n",
        "    \"outtmpl\": f'/content/drive/MyDrive/{song_name}',  # this is where you can edit how you'd like the filenames to be formatted\n",
        "}\n",
        "def download_from_url(url):\n",
        "    ydl.download([url])\n",
        "    # stream = ffmpeg.input('output.m4a')\n",
        "    # stream = ffmpeg.output(stream, 'output.wav')\n",
        "\n",
        "\n",
        "with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "\n",
        "\n",
        "      download_from_url(url)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_pxVhtdhV0Pd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Demucs for Separating Audio\n",
        "!python3 -m pip install -U demucs"
      ],
      "metadata": {
        "cellView": "form",
        "id": "VuC_nJl7Vta-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Start Separate Vocal and Instrument using Demucs\n",
        "#@markdown This program is standart separating Vocal and Instrument.\n",
        "#@markdown Use webUI for more feature.\n",
        "import subprocess\n",
        "input_file = \"/content/drive/MyDrive/Idol.wav\" #@param {type:\"string\"}\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/separated\"\n",
        "\n",
        "command = f\"demucs --two-stems=vocals {input_file}\"\n",
        "result = subprocess.run(command.split(), stdout=subprocess.PIPE)\n",
        "print(result.stdout.decode())"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MFbAFJ48VowB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#title Inference\n",
        "%cd /content/drive/MyDrive/project-main\n",
        "transpose = 0#@param {type:\"integer\"}\n",
        "input_path = \"audios/someguy.mp3\"#@param {type:\"string\"}\n",
        "index_path = \"logs/My-Voice/added_IVF439_Flat_nprobe_1_My-Voice_v2.index\"#@param {type:\"string\"}\n",
        "f0_method = \"mangio-crepe\" # @param [\"rmvpe\", \"pm\", \"mangio-crepe\", \"crepe\", \"dio\", \"harvest\"]\n",
        "opt_path = \"audios/cli_output.wav\"#@param {type:\"string\"}\n",
        "model_name = \"My-Voice.pth\"#@param {type:\"string\"}\n",
        "index_rate = \"0.6\" #@param {type:\"string\"}\n",
        "volume_normalization = 0 # @param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "consonant_protection = 0 # @param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "!rm $opt_path\n",
        "!python tools/infer_cli.py --f0up_key $transpose \\\n",
        "--input_path $input_path \\\n",
        "--index_path $index_path \\\n",
        "--f0method $f0_method \\\n",
        "--opt_path $opt_path \\\n",
        "--model_name $model_name \\\n",
        "--index_rate $index_rate \\\n",
        "--device cuda:0 \\\n",
        "--is_half True \\\n",
        "--filter_radius 3 \\\n",
        "--resample_sr 0 \\\n",
        "--rms_mix_rate $volume_normalization \\\n",
        "--protect $consonant_protection\n",
        "\n",
        "import IPython.display as ipd\n",
        "ipd.clear_output()\n",
        "ipd.Audio(opt_path)"
      ],
      "metadata": {
        "id": "Fz3XSI8GrXra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title OR Open the GUI (Banned for free Colab Notebooks)\n",
        "#@markdown <small> Enter your ngrok authtoken to open tensorboard. Get one here: https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "ngrok_authtoken = \"\"#@param {type:\"string\"}\n",
        "!ngrok config add-authtoken {ngrok_authtoken}\n",
        "if not 'installed' in locals():\n",
        "    %cd /content\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    from IPython.display import clear_output\n",
        "    from ipywidgets import Button\n",
        "    import os\n",
        "    if not os.path.exists('/content/drive'):\n",
        "        print(\"Your drive is not mounted. Creating Fake Drive.\")\n",
        "        os.makedirs('/content/drive/MyDrive')\n",
        "    if not os.path.exists('/content/drive/MyDrive/project-main'):\n",
        "        !wget https://huggingface.co/{source}/project/resolve/main/project-main.zip -O '/content/project-main.zip' && unzip -n 'project-main.zip' -d /content/drive/MyDrive\n",
        "    !cd '/content/drive/MyDrive/project-main' && python download_files.py && pip install -r 'requirements.txt'\n",
        "    !rm /content/project-main.zip\n",
        "    !rm -r /content/sample_data\n",
        "    !mkdir -p /content/dataset\n",
        "    !pip install pyngrok\n",
        "    !pip install tensorflow==2.12.0\n",
        "    clear_output()\n",
        "    Button(description=\"\\u2714 Success\", button_style=\"success\")\n",
        "    installed = True\n",
        "tensorboard = True #@param {type:\"boolean\"}\n",
        "%cd /content/drive/MyDrive/project-main\n",
        "from pyngrok import ngrok\n",
        "ngrok.kill()\n",
        "if tensorboard:\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir ./logs --port=8888\n",
        "    print(\"Tensorboard NGROK URL:\",end=\"\")\n",
        "    ngrok_url = ngrok.connect(8888)\n",
        "    print(ngrok_url)\n",
        "    !python app.py --colab"
      ],
      "metadata": {
        "id": "DZDKirCM0F9g",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RVC V2 ORIGINAL BY [Rejekts](https://colab.research.google.com/drive/1r4IRL0UA7JEoZ0ZK8PKfMyTIBHKpyhcw#scrollTo=Fz3XSI8GrXra)\n",
        "\n",
        "\n",
        "remake by [Laynz28](https://github.com/laynz28)\n",
        "\n",
        "\n",
        "[![](https://media.tenor.com/LMBl17d9rWIAAAAi/fnf-boyfriend.gif)](https://github.com/laynz28)"
      ],
      "metadata": {
        "id": "x3qeVxmTV6ab"
      }
    }
  ]
}