{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/laynz28/RCV-AI-COVER-ALL/blob/main/RVC_AI_COVER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmlBOuMKSvDV"
      },
      "source": [
        "# 1. Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "OA3CyHOtzm4d"
      },
      "outputs": [],
      "source": [
        "#@title Test Runtime\n",
        "!nvidia-smi\n",
        "!nvcc -V\n",
        "!free -h"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Installation Dependencies\n",
        "!pip install yt_dlp\n",
        "!pip install ffmpeg\n",
        "!mkdir youtubeaudio\n",
        "!python3 -m pip install -U demucs\n",
        "!pip install yt_dlp\n",
        "!pip install ffmpeg\n",
        "!apt-get -y install build-essential python3-dev ffmpeg\n",
        "!pip3 install --upgrade setuptools wheel\n",
        "!pip3 install --upgrade pip\n",
        "!pip3 install faiss-gpu fairseq gradio ffmpeg ffmpeg-python praat-parselmouth pyworld numpy==1.23.5 numba==0.56.4 librosa==0.9.2\n",
        "!apt -y install -qq aria2\n",
        "!pip install mega.py --quiet\n",
        "!pip install gdown --quiet\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import clear_output\n",
        "import os, shutil\n",
        "success=widgets.Button(description=\"\\u2714 Done\",\n",
        "disabled=True, button_style=\"success\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "F5PWjKHEkjsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwu07JgqoFON",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Mount Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E22J0T-Uwt21"
      },
      "source": [
        "# 2.  download wav audio from YOUTUBE and SEPARATE VOCAL & MUSIC"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Start Separate Vocal and Instrument using Demucs\n",
        "#@markdown This program is standart separating Vocal and Instrument.\n",
        "#@markdown Use webUI for more feature.\n",
        "import subprocess\n",
        "input_file = \"\" #@param {type:\"string\"}\n",
        "OUTPUT_DIR = \"/content/separated\"\n",
        "\n",
        "command = f\"demucs --two-stems=vocals {input_file}\"\n",
        "result = subprocess.run(command.split(), stdout=subprocess.PIPE)\n",
        "print(result.stdout.decode())\n",
        "#input_file = input(\"Masukkan file audio: \")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "N7_uVtDO102N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1myplxnxHz5"
      },
      "source": [
        "# 3. Install to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rahDvITupjG",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Install to Google Drive (for Resuming Training & Automatic Saving)\n",
        "#@markdown <small> This Notebook is based on another found in: https://github.com/ardha27/AI-Song-Cover-RVC < Visit this repo to read more and support.\n",
        "%cd /content\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "from IPython.display import clear_output\n",
        "from ipywidgets import Button\n",
        "import os\n",
        "if not os.path.exists('/content/drive'):\n",
        "    print(\"Your drive is not mounted. Creating Fake Drive.\")\n",
        "    os.makedirs('/content/drive/MyDrive')\n",
        "source = \"Rejekts\"\n",
        "!wget https://huggingface.co/{source}/project/resolve/main/project-main.zip -O '/content/project-main.zip' && unzip -n 'project-main.zip' -d /content/drive/MyDrive\n",
        "!cd '/content/drive/MyDrive/project-main' && python download_files.py && pip install -r 'requirements-safe.txt'\n",
        "!pip install pyngrok tensorflow==2.12.0\n",
        "!rm /content/project-main.zip\n",
        "!rm -r /content/sample_data\n",
        "!mkdir -p /content/dataset\n",
        "clear_output()\n",
        "Button(description=\"\\u2714 Success\", button_style=\"success\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#make dataset"
      ],
      "metadata": {
        "id": "eHlKomtJjZoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " #@title Input Form\n",
        "\n",
        "Mode = \"Splitting\" #@param [\"Separate\", \"Splitting\"]\n",
        "dataset = \"Youtube\" #@param [\"Youtube\", \"Drive\"]\n",
        "url = \"your YouTube URL\" #@param {type:\"string\"}\n",
        "drive_path = \"\" #@param {type:\"string\"}\n",
        "#@markdown the audio name must be the same as the patch drive name if using Google Drive\n",
        "AUDIO_NAME = \"\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "4LWn31qrjbUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Youtube WAV\n",
        "from __future__ import unicode_literals\n",
        "\n",
        "if dataset == \"Drive\":\n",
        "  print(\"Dataset is set to Drive. Skipping this section\")\n",
        "elif dataset == \"Youtube\":\n",
        "  import yt_dlp\n",
        "  import ffmpeg\n",
        "  import sys\n",
        "\n",
        "\n",
        "  ydl_opts = {\n",
        "      'format': 'bestaudio/best',\n",
        "  #    'outtmpl': 'output.%(ext)s',\n",
        "      'postprocessors': [{\n",
        "          'key': 'FFmpegExtractAudio',\n",
        "          'preferredcodec': 'wav',\n",
        "      }],\n",
        "      \"outtmpl\": f'youtubeaudio/{AUDIO_NAME}',  # this is where you can edit how you'd like the filenames to be formatted\n",
        "  }\n",
        "  def download_from_url(url):\n",
        "      ydl.download([url])\n",
        "      # stream = ffmpeg.input('output.m4a')\n",
        "      # stream = ffmpeg.output(stream, 'output.wav')\n",
        "\n",
        "\n",
        "  with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "\n",
        "        download_from_url(url)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "14H6ja5HkAL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Install Demucs for Separating Audio\n",
        "!python3 -m pip install -U demucs"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fU3DgPcukE_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Separate Vocal and Instrument/Noise using Demucs\n",
        "import subprocess\n",
        "AUDIO_INPUT = f\"/content/youtubeaudio/{AUDIO_NAME}.wav\"\n",
        "\n",
        "if dataset == \"Drive\":\n",
        "  command = f\"demucs --two-stems=vocals {drive_path}\"\n",
        "elif dataset == \"Youtube\":\n",
        "  command = f\"demucs --two-stems=vocals {AUDIO_INPUT}\"\n",
        "\n",
        "result = subprocess.run(command.split(), stdout=subprocess.PIPE)\n",
        "print(result.stdout.decode())"
      ],
      "metadata": {
        "cellView": "form",
        "id": "Y9pnVjP4kHso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/drive/MyDrive/audio/{AUDIO_NAME}\n",
        "!cp -r /content/separated/htdemucs/{AUDIO_NAME}/* /content/drive/MyDrive/audio/{AUDIO_NAME}\n",
        "if dataset == \"Youtube\":\n",
        "  !cp -r /content/youtubeaudio/{AUDIO_NAME}.wav /content/drive/MyDrive/audio/{AUDIO_NAME}"
      ],
      "metadata": {
        "id": "mGNBj3vAkKSS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Split The Audio into Smaller Duration Before Training\n",
        "if Mode == \"Separate\":\n",
        "    print(\"Mode is set to Separate. Skipping this section\")\n",
        "elif Mode ==  \"Splitting\":\n",
        "  !pip install numpy\n",
        "  !pip install librosa\n",
        "  !pip install soundfile\n",
        "  !mkdir -p dataset/{AUDIO_NAME}\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile\n",
        "\n",
        "\n",
        "# This function is obtained from librosa.\n",
        "def get_rms(\n",
        "    y,\n",
        "    *,\n",
        "    frame_length=2048,\n",
        "    hop_length=512,\n",
        "    pad_mode=\"constant\",\n",
        "):\n",
        "    padding = (int(frame_length // 2), int(frame_length // 2))\n",
        "    y = np.pad(y, padding, mode=pad_mode)\n",
        "\n",
        "    axis = -1\n",
        "    # put our new within-frame axis at the end for now\n",
        "    out_strides = y.strides + tuple([y.strides[axis]])\n",
        "    # Reduce the shape on the framing axis\n",
        "    x_shape_trimmed = list(y.shape)\n",
        "    x_shape_trimmed[axis] -= frame_length - 1\n",
        "    out_shape = tuple(x_shape_trimmed) + tuple([frame_length])\n",
        "    xw = np.lib.stride_tricks.as_strided(\n",
        "        y, shape=out_shape, strides=out_strides\n",
        "    )\n",
        "    if axis < 0:\n",
        "        target_axis = axis - 1\n",
        "    else:\n",
        "        target_axis = axis + 1\n",
        "    xw = np.moveaxis(xw, -1, target_axis)\n",
        "    # Downsample along the target axis\n",
        "    slices = [slice(None)] * xw.ndim\n",
        "    slices[axis] = slice(0, None, hop_length)\n",
        "    x = xw[tuple(slices)]\n",
        "\n",
        "    # Calculate power\n",
        "    power = np.mean(np.abs(x) ** 2, axis=-2, keepdims=True)\n",
        "\n",
        "    return np.sqrt(power)\n",
        "\n",
        "\n",
        "class Slicer:\n",
        "    def __init__(self,\n",
        "                 sr: int,\n",
        "                 threshold: float = -40.,\n",
        "                 min_length: int = 5000,\n",
        "                 min_interval: int = 300,\n",
        "                 hop_size: int = 20,\n",
        "                 max_sil_kept: int = 5000):\n",
        "        if not min_length >= min_interval >= hop_size:\n",
        "            raise ValueError('The following condition must be satisfied: min_length >= min_interval >= hop_size')\n",
        "        if not max_sil_kept >= hop_size:\n",
        "            raise ValueError('The following condition must be satisfied: max_sil_kept >= hop_size')\n",
        "        min_interval = sr * min_interval / 1000\n",
        "        self.threshold = 10 ** (threshold / 20.)\n",
        "        self.hop_size = round(sr * hop_size / 1000)\n",
        "        self.win_size = min(round(min_interval), 4 * self.hop_size)\n",
        "        self.min_length = round(sr * min_length / 1000 / self.hop_size)\n",
        "        self.min_interval = round(min_interval / self.hop_size)\n",
        "        self.max_sil_kept = round(sr * max_sil_kept / 1000 / self.hop_size)\n",
        "\n",
        "    def _apply_slice(self, waveform, begin, end):\n",
        "        if len(waveform.shape) > 1:\n",
        "            return waveform[:, begin * self.hop_size: min(waveform.shape[1], end * self.hop_size)]\n",
        "        else:\n",
        "            return waveform[begin * self.hop_size: min(waveform.shape[0], end * self.hop_size)]\n",
        "\n",
        "    def slice(self, waveform):\n",
        "        if len(waveform.shape) > 1:\n",
        "            samples = waveform.mean(axis=0)\n",
        "        else:\n",
        "            samples = waveform\n",
        "        if samples.shape[0] <= self.min_length:\n",
        "            return [waveform]\n",
        "        rms_list = get_rms(y=samples, frame_length=self.win_size, hop_length=self.hop_size).squeeze(0)\n",
        "        sil_tags = []\n",
        "        silence_start = None\n",
        "        clip_start = 0\n",
        "        for i, rms in enumerate(rms_list):\n",
        "            # Keep looping while frame is silent.\n",
        "            if rms < self.threshold:\n",
        "                # Record start of silent frames.\n",
        "                if silence_start is None:\n",
        "                    silence_start = i\n",
        "                continue\n",
        "            # Keep looping while frame is not silent and silence start has not been recorded.\n",
        "            if silence_start is None:\n",
        "                continue\n",
        "            # Clear recorded silence start if interval is not enough or clip is too short\n",
        "            is_leading_silence = silence_start == 0 and i > self.max_sil_kept\n",
        "            need_slice_middle = i - silence_start >= self.min_interval and i - clip_start >= self.min_length\n",
        "            if not is_leading_silence and not need_slice_middle:\n",
        "                silence_start = None\n",
        "                continue\n",
        "            # Need slicing. Record the range of silent frames to be removed.\n",
        "            if i - silence_start <= self.max_sil_kept:\n",
        "                pos = rms_list[silence_start: i + 1].argmin() + silence_start\n",
        "                if silence_start == 0:\n",
        "                    sil_tags.append((0, pos))\n",
        "                else:\n",
        "                    sil_tags.append((pos, pos))\n",
        "                clip_start = pos\n",
        "            elif i - silence_start <= self.max_sil_kept * 2:\n",
        "                pos = rms_list[i - self.max_sil_kept: silence_start + self.max_sil_kept + 1].argmin()\n",
        "                pos += i - self.max_sil_kept\n",
        "                pos_l = rms_list[silence_start: silence_start + self.max_sil_kept + 1].argmin() + silence_start\n",
        "                pos_r = rms_list[i - self.max_sil_kept: i + 1].argmin() + i - self.max_sil_kept\n",
        "                if silence_start == 0:\n",
        "                    sil_tags.append((0, pos_r))\n",
        "                    clip_start = pos_r\n",
        "                else:\n",
        "                    sil_tags.append((min(pos_l, pos), max(pos_r, pos)))\n",
        "                    clip_start = max(pos_r, pos)\n",
        "            else:\n",
        "                pos_l = rms_list[silence_start: silence_start + self.max_sil_kept + 1].argmin() + silence_start\n",
        "                pos_r = rms_list[i - self.max_sil_kept: i + 1].argmin() + i - self.max_sil_kept\n",
        "                if silence_start == 0:\n",
        "                    sil_tags.append((0, pos_r))\n",
        "                else:\n",
        "                    sil_tags.append((pos_l, pos_r))\n",
        "                clip_start = pos_r\n",
        "            silence_start = None\n",
        "        # Deal with trailing silence.\n",
        "        total_frames = rms_list.shape[0]\n",
        "        if silence_start is not None and total_frames - silence_start >= self.min_interval:\n",
        "            silence_end = min(total_frames, silence_start + self.max_sil_kept)\n",
        "            pos = rms_list[silence_start: silence_end + 1].argmin() + silence_start\n",
        "            sil_tags.append((pos, total_frames + 1))\n",
        "        # Apply and return slices.\n",
        "        if len(sil_tags) == 0:\n",
        "            return [waveform]\n",
        "        else:\n",
        "            chunks = []\n",
        "            if sil_tags[0][0] > 0:\n",
        "                chunks.append(self._apply_slice(waveform, 0, sil_tags[0][0]))\n",
        "            for i in range(len(sil_tags) - 1):\n",
        "                chunks.append(self._apply_slice(waveform, sil_tags[i][1], sil_tags[i + 1][0]))\n",
        "            if sil_tags[-1][1] < total_frames:\n",
        "                chunks.append(self._apply_slice(waveform, sil_tags[-1][1], total_frames))\n",
        "            return chunks\n",
        "\n",
        "if Mode == \"Separate\":\n",
        "    print(\"Mode is set to Separate. Skipping this section\")\n",
        "\n",
        "elif Mode ==  \"Splitting\":\n",
        "  audio, sr = librosa.load(f'/content/separated/htdemucs/{AUDIO_NAME}/vocals.wav', sr=None, mono=False)  # Load an audio file with librosa.\n",
        "  slicer = Slicer(\n",
        "      sr=sr,\n",
        "      threshold=-40,\n",
        "      min_length=5000,\n",
        "      min_interval=500,\n",
        "      hop_size=10,\n",
        "      max_sil_kept=500\n",
        "  )\n",
        "  chunks = slicer.slice(audio)\n",
        "  for i, chunk in enumerate(chunks):\n",
        "      if len(chunk.shape) > 1:\n",
        "          chunk = chunk.T  # Swap axes if the audio is stereo.\n",
        "      soundfile.write(f'/content/dataset/{AUDIO_NAME}/split_{i}.wav', chunk, sr)  # Save sliced audio files with soundfile."
      ],
      "metadata": {
        "cellView": "form",
        "id": "oe_t4dYXkNCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if Mode == \"Separate\":\n",
        "    print(\"Mode is set to Separate. Skipping this section\")\n",
        "elif Mode ==  \"Splitting\":\n",
        "  !mkdir -p /content/drive/MyDrive/dataset/{AUDIO_NAME}\n",
        "  !cp -r /content/dataset/{AUDIO_NAME}/* /content/drive/MyDrive/dataset/{AUDIO_NAME}"
      ],
      "metadata": {
        "id": "k1BpQ4lgkW1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DOWNLOAD YOUTUBE WAV"
      ],
      "metadata": {
        "id": "cQ4BfSk_6xe2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Separate vocal if you want\n",
        "Mode = \"Separate\" #@param [\"Separate\"]\n",
        "url = \"\" #@param {type:\"string\"}\n",
        "drive_path = \"\" #@param {type:\"string\"}\n",
        "AUDIO_NAME = \"\" #@param {type:\"string\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6va3pzPq8ufZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download Youtube WAV\n",
        "from __future__ import unicode_literals\n",
        "\n",
        "if dataset == \"Drive\":\n",
        "  print(\"Dataset is set to Drive. Skipping this section\")\n",
        "elif dataset == \"Youtube\":\n",
        "  import yt_dlp\n",
        "  import ffmpeg\n",
        "  import sys\n",
        "\n",
        "\n",
        "  ydl_opts = {\n",
        "      'format': 'bestaudio/best',\n",
        "  #    'outtmpl': 'output.%(ext)s',\n",
        "      'postprocessors': [{\n",
        "          'key': 'FFmpegExtractAudio',\n",
        "          'preferredcodec': 'wav',\n",
        "      }],\n",
        "      \"outtmpl\": f'youtubeaudio/{AUDIO_NAME}',  # this is where you can edit how you'd like the filenames to be formatted\n",
        "  }\n",
        "  def download_from_url(url):\n",
        "      ydl.download([url])\n",
        "      # stream = ffmpeg.input('output.m4a')\n",
        "      # stream = ffmpeg.output(stream, 'output.wav')\n",
        "\n",
        "\n",
        "  with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "\n",
        "        download_from_url(url)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "OB1k9uhS80v0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Separate Vocal and Instrument/Noise using Demucs\n",
        "import subprocess\n",
        "AUDIO_INPUT = f\"/content/youtubeaudio/{AUDIO_NAME}.wav\"\n",
        "\n",
        "if dataset == \"Drive\":\n",
        "  command = f\"demucs --two-stems=vocals {drive_path}\"\n",
        "elif dataset == \"Youtube\":\n",
        "  command = f\"demucs --two-stems=vocals {AUDIO_INPUT}\"\n",
        "\n",
        "result = subprocess.run(command.split(), stdout=subprocess.PIPE)\n",
        "print(result.stdout.decode())"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LC3FyzVU87Pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/drive/MyDrive/audio/{AUDIO_NAME}\n",
        "!cp -r /content/separated/htdemucs/{AUDIO_NAME}/* /content/drive/MyDrive/audio/{AUDIO_NAME}\n",
        "if dataset == \"Youtube\":\n",
        "  !cp -r /content/youtubeaudio/{AUDIO_NAME}.wav /content/drive/MyDrive/audio/{AUDIO_NAME}"
      ],
      "metadata": {
        "id": "K-kcXf_y9BG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGuCk9_KUkYI"
      },
      "source": [
        "#  Download models\n",
        "\n",
        "NAME = GIVE A NAME FOR MODELS\n",
        "\n",
        "\n",
        "URL = YOUR VOICE MODELS URL FORM HUGGINGFACE MEGA DRIVE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download The Model\n",
        "from mega import Mega\n",
        "import os\n",
        "MODEL = \"LYN\"  #@param {type:\"string\"}\n",
        "MODELEPOCH = ''\n",
        "url='https://huggingface.co/spaces/LaynzKunz/RANDDOM_RCV/resolve/main/Laynz.zip'#@param {type:\"string\"}\n",
        "MODELZIP = MODEL + '.zip'\n",
        "modelname_path='/content/zips/'+MODELZIP\n",
        "if url != '':\n",
        "  !mkdir -p /content/drive/MyDrive/project-main/logs/{MODEL}\n",
        "  !mkdir -p /content/zips/\n",
        "  if \"drive.google.com\" in url:\n",
        "    !gdown $url --fuzzy -O $modelname_path\n",
        "  elif \"mega.nz\" in url:\n",
        "    m = Mega()\n",
        "    m.download_url(url, '/content/zips')\n",
        "  else:\n",
        "    !wget $url -O /content/zips/{MODELZIP}\n",
        "  for filename in os.listdir(\"/content/zips\"):\n",
        "    if filename.endswith(\".zip\"):\n",
        "      zip_file = os.path.join(\"/content/zips\", filename)\n",
        "      shutil.unpack_archive(zip_file, \"/content/unzips\", 'zip')\n",
        "  #Move model into logs folder\n",
        "  for root, dirs, files in os.walk('/content/unzips'):\n",
        "    for file in files:\n",
        "      if \"G_\" in file:\n",
        "        MODELEPOCH = file.split(\"G_\")[1].split(\".\")[0]\n",
        "    if MODELEPOCH == '':\n",
        "      MODELEPOCH = '404'\n",
        "    for file in files:\n",
        "      file_path = os.path.join(root, file)\n",
        "      if file.endswith(\".npy\") or file.endswith(\".index\"):\n",
        "        !mv {file_path} /content/drive/MyDrive/project-main/assets/logs/{MODEL}/\n",
        "      elif \"G_\" not in file and \"D_\" not in file and file.endswith(\".pth\"):\n",
        "        !mv {file_path} /content/drive/MyDrive/project-main/assets/weights/{MODEL}.pth\n",
        "\n",
        "\n",
        "  clear_output()\n",
        "  display(success)\n",
        "else:\n",
        "  print(\"URL cannot be left empty. If you don't want to download a model now, just skip this step.\")"
      ],
      "metadata": {
        "id": "c36wzmDQ0ftc",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlerbKhDriZ4"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KvlxLQY0r42b"
      },
      "outputs": [],
      "source": [
        "#@title 1.Preprocess Data\n",
        "%cd /content/drive/MyDrive/project-main\n",
        "model_name = 'My-Voice' #@param {type:\"string\"}\n",
        "#@markdown <small> Enter the path to your dataset folder (a folder with audios of the vocals you will train on), or if you want just upload the audios using the File Manager into the 'dataset' folder.\n",
        "dataset_folder = '/content/drive/MyDrive/dataset' #@param {type:\"string\"}\n",
        "while len(os.listdir(dataset_folder)) < 1:\n",
        "    input(\"Your dataset folder is empty.\")\n",
        "!mkdir -p ./logs/{model_name}\n",
        "with open(f'./logs/{model_name}/preprocess.log','w') as f:\n",
        "    print(\"Starting...\")\n",
        "!python infer/modules/train/preprocess.py {dataset_folder} 40000 2 ./logs/{model_name} False 3.0 > /dev/null 2>&1\n",
        "with open(f'./logs/{model_name}/preprocess.log','r') as f:\n",
        "    if 'end preprocess' in f.read():\n",
        "        clear_output()\n",
        "        display(Button(description=\"\\u2714 Success\", button_style=\"success\"))\n",
        "    else:\n",
        "        print(\"Error preprocessing data... Make sure your dataset folder is correct.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ruG-XVMXrjjf"
      },
      "outputs": [],
      "source": [
        "#@title 2.Extract Features\n",
        "f0method = \"rmvpe_gpu\" # @param [\"pm\", \"harvest\", \"rmvpe\", \"rmvpe_gpu\"]\n",
        "%cd /content/drive/MyDrive/project-main\n",
        "with open(f'./logs/{model_name}/extract_f0_feature.log','w') as f:\n",
        "    print(\"Starting...\")\n",
        "if f0method != \"rmvpe_gpu\":\n",
        "    !python infer/modules/train/extract/extract_f0_print.py ./logs/{model_name} 2 {f0method}\n",
        "else:\n",
        "    !python infer/modules/train/extract/extract_f0_rmvpe.py 1 0 0 ./logs/{model_name} True\n",
        "!python infer/modules/train/extract_feature_print.py cuda:0 1 0 0 ./logs/{model_name} v2\n",
        "with open(f'./logs/{model_name}/extract_f0_feature.log','r') as f:\n",
        "    if 'all-feature-done' in f.read():\n",
        "        clear_output()\n",
        "        display(Button(description=\"\\u2714 Success\", button_style=\"success\"))\n",
        "    else:\n",
        "        print(\"Error preprocessing data... Make sure your data was preprocessed.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Mg2P5eJFr9R0"
      },
      "outputs": [],
      "source": [
        "#@title 3.Train Index\n",
        "import numpy as np\n",
        "import faiss\n",
        "%cd /content/drive/MyDrive/project-main\n",
        "def train_index(exp_dir1, version19):\n",
        "    exp_dir = \"logs/%s\" % (exp_dir1)\n",
        "    os.makedirs(exp_dir, exist_ok=True)\n",
        "    feature_dir = (\n",
        "        \"%s/3_feature256\" % (exp_dir)\n",
        "        if version19 == \"v1\"\n",
        "        else \"%s/3_feature768\" % (exp_dir)\n",
        "    )\n",
        "    if not os.path.exists(feature_dir):\n",
        "        return \"请先进行特征提取!\"\n",
        "    listdir_res = list(os.listdir(feature_dir))\n",
        "    if len(listdir_res) == 0:\n",
        "        return \"请先进行特征提取！\"\n",
        "    infos = []\n",
        "    npys = []\n",
        "    for name in sorted(listdir_res):\n",
        "        phone = np.load(\"%s/%s\" % (feature_dir, name))\n",
        "        npys.append(phone)\n",
        "    big_npy = np.concatenate(npys, 0)\n",
        "    big_npy_idx = np.arange(big_npy.shape[0])\n",
        "    np.random.shuffle(big_npy_idx)\n",
        "    big_npy = big_npy[big_npy_idx]\n",
        "    if big_npy.shape[0] > 2e5:\n",
        "        infos.append(\"Trying doing kmeans %s shape to 10k centers.\" % big_npy.shape[0])\n",
        "        yield \"\\n\".join(infos)\n",
        "        try:\n",
        "            big_npy = (\n",
        "                MiniBatchKMeans(\n",
        "                    n_clusters=10000,\n",
        "                    verbose=True,\n",
        "                    batch_size=256 * config.n_cpu,\n",
        "                    compute_labels=False,\n",
        "                    init=\"random\",\n",
        "                )\n",
        "                .fit(big_npy)\n",
        "                .cluster_centers_\n",
        "            )\n",
        "        except:\n",
        "            info = traceback.format_exc()\n",
        "            logger.info(info)\n",
        "            infos.append(info)\n",
        "            yield \"\\n\".join(infos)\n",
        "\n",
        "    np.save(\"%s/total_fea.npy\" % exp_dir, big_npy)\n",
        "    n_ivf = min(int(16 * np.sqrt(big_npy.shape[0])), big_npy.shape[0] // 39)\n",
        "    infos.append(\"%s,%s\" % (big_npy.shape, n_ivf))\n",
        "    yield \"\\n\".join(infos)\n",
        "    index = faiss.index_factory(256 if version19 == \"v1\" else 768, \"IVF%s,Flat\" % n_ivf)\n",
        "    infos.append(\"training\")\n",
        "    yield \"\\n\".join(infos)\n",
        "    index_ivf = faiss.extract_index_ivf(index)  #\n",
        "    index_ivf.nprobe = 1\n",
        "    index.train(big_npy)\n",
        "    faiss.write_index(\n",
        "        index,\n",
        "        \"%s/trained_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n",
        "        % (exp_dir, n_ivf, index_ivf.nprobe, exp_dir1, version19),\n",
        "    )\n",
        "\n",
        "    infos.append(\"adding\")\n",
        "    yield \"\\n\".join(infos)\n",
        "    batch_size_add = 8192\n",
        "    for i in range(0, big_npy.shape[0], batch_size_add):\n",
        "        index.add(big_npy[i : i + batch_size_add])\n",
        "    faiss.write_index(\n",
        "        index,\n",
        "        \"%s/added_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n",
        "        % (exp_dir, n_ivf, index_ivf.nprobe, exp_dir1, version19),\n",
        "    )\n",
        "    infos.append(\n",
        "        \"成功构建索引，added_IVF%s_Flat_nprobe_%s_%s_%s.index\"\n",
        "        % (n_ivf, index_ivf.nprobe, exp_dir1, version19)\n",
        "    )\n",
        "\n",
        "training_log = train_index(model_name, 'v2')\n",
        "\n",
        "for line in training_log:\n",
        "    print(line)\n",
        "    if 'adding' in line:\n",
        "        clear_output()\n",
        "        display(Button(description=\"\\u2714 Success\", button_style=\"success\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IkvkQky6sEWM"
      },
      "outputs": [],
      "source": [
        " #@title 4.Train Model\n",
        "#@markdown don't change this!\n",
        "ngrok_authtoken = \"2VqrgGnzNs2bSC0racuiPMMq52U_2sW8K1uh5KTb7rkpNrT7H\"#@param {type:\"string\"}\n",
        "!ngrok config add-authtoken {ngrok_authtoken}\n",
        "#%cd /content/drive/MyDrive/project-main\n",
        "from random import shuffle\n",
        "import json\n",
        "import os\n",
        "import pathlib\n",
        "from subprocess import Popen, PIPE, STDOUT\n",
        "from pyngrok import ngrok\n",
        "now_dir=os.getcwd()\n",
        "#@markdown <small> Enter the name of your model again. It must be the same you chose before.\n",
        "model_name = 'My-Voice'#@param {type:\"string\"}\n",
        "#@markdown <small> Choose how often to save the model and how much training you want it to have.\n",
        "save_frequency = 50 # @param {type:\"slider\", min:5, max:50, step:5}\n",
        "epochs = 400 # @param {type:\"slider\", min:10, max:1000, step:10}\n",
        "#@markdown <small> ONLY cache datasets under 10 minutes long. Otherwise leave this unchecked.\n",
        "cache = True #@param {type:\"boolean\"}\n",
        "# Remove the logging setup\n",
        "\n",
        "def click_train(\n",
        "    exp_dir1,\n",
        "    sr2,\n",
        "    if_f0_3,\n",
        "    spk_id5,\n",
        "    save_epoch10,\n",
        "    total_epoch11,\n",
        "    batch_size12,\n",
        "    if_save_latest13,\n",
        "    pretrained_G14,\n",
        "    pretrained_D15,\n",
        "    gpus16,\n",
        "    if_cache_gpu17,\n",
        "    if_save_every_weights18,\n",
        "    version19,\n",
        "):\n",
        "    # 生成filelist\n",
        "    exp_dir = \"%s/logs/%s\" % (now_dir, exp_dir1)\n",
        "    os.makedirs(exp_dir, exist_ok=True)\n",
        "    gt_wavs_dir = \"%s/0_gt_wavs\" % (exp_dir)\n",
        "    feature_dir = (\n",
        "        \"%s/3_feature256\" % (exp_dir)\n",
        "        if version19 == \"v1\"\n",
        "        else \"%s/3_feature768\" % (exp_dir)\n",
        "    )\n",
        "    if if_f0_3:\n",
        "        f0_dir = \"%s/2a_f0\" % (exp_dir)\n",
        "        f0nsf_dir = \"%s/2b-f0nsf\" % (exp_dir)\n",
        "        names = (\n",
        "            set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)])\n",
        "            & set([name.split(\".\")[0] for name in os.listdir(feature_dir)])\n",
        "            & set([name.split(\".\")[0] for name in os.listdir(f0_dir)])\n",
        "            & set([name.split(\".\")[0] for name in os.listdir(f0nsf_dir)])\n",
        "        )\n",
        "    else:\n",
        "        names = set([name.split(\".\")[0] for name in os.listdir(gt_wavs_dir)]) & set(\n",
        "            [name.split(\".\")[0] for name in os.listdir(feature_dir)]\n",
        "        )\n",
        "    opt = []\n",
        "    for name in names:\n",
        "        if if_f0_3:\n",
        "            opt.append(\n",
        "                \"%s/%s.wav|%s/%s.npy|%s/%s.wav.npy|%s/%s.wav.npy|%s\"\n",
        "                % (\n",
        "                    gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    feature_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    f0_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    f0nsf_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    spk_id5,\n",
        "                )\n",
        "            )\n",
        "        else:\n",
        "            opt.append(\n",
        "                \"%s/%s.wav|%s/%s.npy|%s\"\n",
        "                % (\n",
        "                    gt_wavs_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    feature_dir.replace(\"\\\\\", \"\\\\\\\\\"),\n",
        "                    name,\n",
        "                    spk_id5,\n",
        "                )\n",
        "            )\n",
        "    fea_dim = 256 if version19 == \"v1\" else 768\n",
        "    if if_f0_3:\n",
        "        for _ in range(2):\n",
        "            opt.append(\n",
        "                \"%s/logs/mute/0_gt_wavs/mute%s.wav|%s/logs/mute/3_feature%s/mute.npy|%s/logs/mute/2a_f0/mute.wav.npy|%s/logs/mute/2b-f0nsf/mute.wav.npy|%s\"\n",
        "                % (now_dir, sr2, now_dir, fea_dim, now_dir, now_dir, spk_id5)\n",
        "            )\n",
        "    else:\n",
        "        for _ in range(2):\n",
        "            opt.append(\n",
        "                \"%s/logs/mute/0_gt_wavs/mute%s.wav|%s/logs/mute/3_feature%s/mute.npy|%s\"\n",
        "                % (now_dir, sr2, now_dir, fea_dim, spk_id5)\n",
        "            )\n",
        "    shuffle(opt)\n",
        "    with open(\"%s/filelist.txt\" % exp_dir, \"w\") as f:\n",
        "        f.write(\"\\n\".join(opt))\n",
        "\n",
        "    # Replace logger.debug, logger.info with print statements\n",
        "    print(\"Write filelist done\")\n",
        "    print(\"Use gpus:\", str(gpus16))\n",
        "    if pretrained_G14 == \"\":\n",
        "        print(\"No pretrained Generator\")\n",
        "    if pretrained_D15 == \"\":\n",
        "        print(\"No pretrained Discriminator\")\n",
        "    if version19 == \"v1\" or sr2 == \"40k\":\n",
        "        config_path = \"configs/v1/%s.json\" % sr2\n",
        "    else:\n",
        "        config_path = \"configs/v2/%s.json\" % sr2\n",
        "    config_save_path = os.path.join(exp_dir, \"config.json\")\n",
        "    if not pathlib.Path(config_save_path).exists():\n",
        "        with open(config_save_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            with open(config_path, \"r\") as config_file:\n",
        "                config_data = json.load(config_file)\n",
        "                json.dump(\n",
        "                    config_data,\n",
        "                    f,\n",
        "                    ensure_ascii=False,\n",
        "                    indent=4,\n",
        "                    sort_keys=True,\n",
        "                )\n",
        "            f.write(\"\\n\")\n",
        "\n",
        "    cmd = (\n",
        "        'python infer/modules/train/train.py -e \"%s\" -sr %s -f0 %s -bs %s -g %s -te %s -se %s %s %s -l %s -c %s -sw %s -v %s'\n",
        "        % (\n",
        "            exp_dir1,\n",
        "            sr2,\n",
        "            1 if if_f0_3 else 0,\n",
        "            batch_size12,\n",
        "            gpus16,\n",
        "            total_epoch11,\n",
        "            save_epoch10,\n",
        "            \"-pg %s\" % pretrained_G14 if pretrained_G14 != \"\" else \"\",\n",
        "            \"-pd %s\" % pretrained_D15 if pretrained_D15 != \"\" else \"\",\n",
        "            1 if if_save_latest13 == True else 0,\n",
        "            1 if if_cache_gpu17 == True else 0,\n",
        "            1 if if_save_every_weights18 == True else 0,\n",
        "            version19,\n",
        "        )\n",
        "    )\n",
        "    # Use PIPE to capture the output and error streams\n",
        "    p = Popen(cmd, shell=True, cwd=now_dir, stdout=PIPE, stderr=STDOUT, bufsize=1, universal_newlines=True)\n",
        "\n",
        "    # Print the command's output as it runs\n",
        "    for line in p.stdout:\n",
        "        print(line.strip())\n",
        "\n",
        "    # Wait for the process to finish\n",
        "    p.wait()\n",
        "    return \"训练结束, 您可查看控制台训练日志或实验文件夹下的train.log\"\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./logs --port=8888\n",
        "print(\"Tensorboard NGROK URL:\",end=\"\")\n",
        "ngrok_url = ngrok.connect(8888)\n",
        "print(ngrok_url)\n",
        "try:\n",
        "    training_log = click_train(\n",
        "        model_name,\n",
        "        '40k',\n",
        "        True,\n",
        "        0,\n",
        "        save_frequency,\n",
        "        epochs,\n",
        "        12,\n",
        "        True,\n",
        "        'assets/pretrained_v2/f0G40k.pth',\n",
        "        'assets/pretrained_v2/f0D40k.pth',\n",
        "        0,\n",
        "        cache,\n",
        "        True,\n",
        "        'v2',\n",
        "    )\n",
        "    print(training_log)\n",
        "except:\n",
        "    ngrok.kill()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ikFsufJsNC0"
      },
      "source": [
        "# INFERENCE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cLYFmj0hsPK_"
      },
      "outputs": [],
      "source": [
        "#@title Inference\n",
        "%cd /content/drive/MyDrive/Retrieval-based-Voice-Conversion-WebUI\n",
        "model_name = \"\"#@param {type:\"string\"}\n",
        "transpose = \"0 \"#@param {type:\"string\"}\n",
        "index_path = \"\"#@param {type:\"string\"}\n",
        "f0_method = \"rmvpe\" # @param [\"rmvpe\", \"pm\", \"harvest\"]\n",
        "input_path = \"\"#@param {type:\"string\"}\n",
        "opt_path = \"\"#@param {type:\"string\"}\n",
        "index_rate = \"0.6\" #@param {type:\"string\"}\n",
        "volume_normalization = 0 # @param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "consonant_protection = 0 # @param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "!rm $opt_path\n",
        "!python tools/infer_cli.py --f0up_key $transpose \\\n",
        "--input_path $input_path \\\n",
        "--index_path $index_path \\\n",
        "--f0method $f0_method \\\n",
        "--opt_path $opt_path \\\n",
        "--model_name $model_name \\\n",
        "--index_rate $index_rate \\\n",
        "--device cuda:0 \\\n",
        "--is_half True \\\n",
        "--filter_radius 3 \\\n",
        "--resample_sr 0 \\\n",
        "--rms_mix_rate $volume_normalization \\\n",
        "--protect $consonant_protection\n",
        "\n",
        "import IPython.display as ipd\n",
        "ipd.clear_output()\n",
        "ipd.Audio(opt_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYhsHY6zZIr6"
      },
      "source": [
        "# (Run webUI)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7vh6vphDwO0b"
      },
      "outputs": [],
      "source": [
        "#@title OR Open the GUI (Banned for free Colab Notebooks)\n",
        "#@markdown <small> Enter your ngrok authtoken to open tensorboard. Get one here: https://dashboard.ngrok.com/get-started/your-authtoken\n",
        "ngrok_authtoken = \"2VqrgGnzNs2bSC0racuiPMMq52U_2sW8K1uh5KTb7rkpNrT7H\"#@param {type:\"string\"}\n",
        "!ngrok config add-authtoken {ngrok_authtoken}\n",
        "if not 'installed' in locals():\n",
        "    %cd /content\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    from IPython.display import clear_output\n",
        "    from ipywidgets import Button\n",
        "    import os\n",
        "    if not os.path.exists('/content/drive'):\n",
        "        print(\"Your drive is not mounted. Creating Fake Drive.\")\n",
        "        os.makedirs('/content/drive/MyDrive')\n",
        "    if not os.path.exists('/content/drive/MyDrive/project-main'):\n",
        "        !wget https://huggingface.co/{source}/project/resolve/main/project-main.zip -O '/content/project-main.zip' && unzip -n 'project-main.zip' -d /content/drive/MyDrive\n",
        "    !cd '/content/drive/MyDrive/project-main' && python download_files.py && pip install -r 'requirements.txt'\n",
        "    !rm /content/project-main.zip\n",
        "    !rm -r /content/sample_data\n",
        "    !mkdir -p /content/dataset\n",
        "    !pip install pyngrok\n",
        "    !pip install tensorflow==2.12.0\n",
        "    clear_output()\n",
        "    Button(description=\"\\u2714 Success\", button_style=\"success\")\n",
        "    installed = True\n",
        "tensorboard = True #@param {type:\"boolean\"}\n",
        "%cd /content/drive/MyDrive/project-main\n",
        "from pyngrok import ngrok\n",
        "ngrok.kill()\n",
        "if tensorboard:\n",
        "    %load_ext tensorboard\n",
        "    %tensorboard --logdir ./logs --port=8888\n",
        "    print(\"Tensorboard NGROK URL:\",end=\"\")\n",
        "    ngrok_url = ngrok.connect(8888)\n",
        "    print(ngrok_url)\n",
        "    !python app.py --colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQpsrCw80wYz"
      },
      "source": [
        "# <center> Confused? Yes Me Too<br />"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "FmlBOuMKSvDV",
        "E22J0T-Uwt21",
        "t1myplxnxHz5",
        "eHlKomtJjZoI",
        "cQ4BfSk_6xe2",
        "sGuCk9_KUkYI",
        "ZlerbKhDriZ4",
        "-ikFsufJsNC0",
        "aYhsHY6zZIr6"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}